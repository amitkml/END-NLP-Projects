{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Based NER using CONLL dataset",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6HQS-mNlN9V"
      },
      "source": [
        "This colab file is created by [Pragnakalp Techlabs](https://www.pragnakalp.com/).\n",
        "\n",
        "You can copy this colab in your drive and then execute the command in given order. For more details on BERT based NER check our blog [BERT Based Named Entity Recognition (NER) Tutorial and Demo](https://www.pragnakalp.com/bert-named-entity-recognition-ner-tutorial-demo/)\n",
        "\n",
        "You can also [purchase the Demo of our BERT based NER system including model fine-tuned on 5 datasets](https://www.pragnakalp.com/buy-bert-based-ner-model-code/).\n",
        "\n",
        "Check all our [NLP Demos on demos.pragnakalp.com](https://demos.pragnakalp.com) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sGQUTKYmNlQ"
      },
      "source": [
        "##**BERT Fine-tuning and Prediction on CONLL 2003:** \n",
        "\n",
        "---\n",
        ">**OVERVIEW**:\n",
        "\n",
        ">**Named Entity Recognition (NER)** also known as information extraction/chunking is the process in which algorithm extracts the real world noun entity from the text data and classifies them into predefined categories like person, place, time, organization, etc.\n",
        "\n",
        "> **CONLL 2003** is most basic dataset, concentrating on four types of named entities related to persons, locations, organizations, and names of miscellaneous entities. CONLL 2003 follow BIO schema which contain four columns separated by a single space.\n",
        "\n",
        ">This colab file shows how to fine-tune BERT Model on **CONLL 2003** dataset by using **KAMALRAJ** Github Repository, and then how to perform the prediction. Using this you can create your own Named Entity Recognition(NER) System.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxsle2Qd2TkF"
      },
      "source": [
        "### **Change Runtime to GPU**\n",
        "\n",
        "> On the main menu, click on **Runtime** and select **Change runtime type**. Set \"**GPU**\" as the hardware accelerator.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeGDviHJMS2D"
      },
      "source": [
        "### **Clone Repository:**\n",
        ">First Step is to clone KAMALKRAJ Github Repository. Below code is command to clone repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvQ_RWMLbbJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fb2303-a60f-4c4b-fdc9-6037bcb3c3f0"
      },
      "source": [
        "!git clone https://github.com/kamalkraj/BERT-NER.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BERT-NER'...\n",
            "remote: Enumerating objects: 249, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 249 (delta 0), reused 0 (delta 0), pack-reused 246\u001b[K\n",
            "Receiving objects: 100% (249/249), 1.67 MiB | 1.28 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufSdczQDPlrB"
      },
      "source": [
        "Use \"ls -l\" command for verfying the repository cloned properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C7bDikoPlQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd578c0c-1e64-42e7-94d3-c37e5f5d47b2"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 6 root root 4096 Jun  1 09:08 \u001b[0m\u001b[01;34mBERT-NER\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 May  6 13:44 \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySa-sua0QJpD"
      },
      "source": [
        "Now go to 'BERT-NER' directory by using below command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwo-o7sfIvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e68fea-e153-48ac-cd7a-c3825e67b436"
      },
      "source": [
        "cd BERT-NER/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BERT-NER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67InEGB6RcZq"
      },
      "source": [
        "**BERT-NER files:** \n",
        "> Use 'ls -l' to check content inside BERT-NER folder. These below files and folders we will use for finetuning and prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SVXck7RRPnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0374e0-113a-416a-bfd3-47dd5d5dbb7e"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 100\n",
            "-rw-r--r-- 1 root root   470 Jun  1 09:08 api.py\n",
            "-rw-r--r-- 1 root root  4674 Jun  1 09:08 bert.py\n",
            "drwxr-xr-x 3 root root  4096 Jun  1 09:08 \u001b[0m\u001b[01;34mcpp-app\u001b[0m/\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 09:08 \u001b[01;34mdata\u001b[0m/\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 09:08 \u001b[01;34mimg\u001b[0m/\n",
            "-rw-r--r-- 1 root root 34523 Jun  1 09:08 LICENSE.txt\n",
            "-rw-r--r-- 1 root root  4777 Jun  1 09:08 README.md\n",
            "-rw-r--r-- 1 root root   173 Jun  1 09:08 requirements.txt\n",
            "-rw-r--r-- 1 root root 27023 Jun  1 09:08 run_ner.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SdW3DFoTLPS"
      },
      "source": [
        "\"requirements.txt\" contains all the pacakages that required for trainig and inference. By using below command install all the pacakages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDphixDqmufw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72390f7c-7961-49fb-ed87-d6f4d986e716"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 2.8MB/s \n",
            "\u001b[?25hCollecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/65/5248be50c55ab7429dd5c11f5e2f9f5865606b80e854ca63139ad1a584f2/torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 23kB/s \n",
            "\u001b[?25hCollecting seqeval==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/b6/6e58b54c0fa343f9c24969cb887f3e76c13d16dded640cc620a914f27dc4/seqeval-0.0.5-py3-none-any.whl\n",
            "Collecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 30.6MB/s \n",
            "\u001b[?25hCollecting Flask==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.0MB/s \n",
            "\u001b[?25hCollecting Flask-Cors==3.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/20/4294e37c3c6936c905f1e9da958c776d7fee54a4512bdb7706d69c8720e6/boto3-1.17.84-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (1.0.1)\n",
            "Collecting botocore<1.21.0,>=1.20.84\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/22/72c81d754bbcb128cba2ad88670c3c320e4594e6ddd8cca6512c3967108c/botocore-1.20.84-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 30.4MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask==1.1.1->-r requirements.txt (line 10)) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.84->boto3->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2.8.1)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449904 sha256=e538d3f8d2b11eb7fc401ca09d515c0c699deb6066bd95002ecfea157013e586\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "Successfully built nltk\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.84 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, tqdm, sacremoses, torch, sentencepiece, pytorch-transformers, seqeval, nltk, Flask, Flask-Cors\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "Successfully installed Flask-1.1.1 Flask-Cors-3.0.8 boto3-1.17.84 botocore-1.20.84 jmespath-0.10.0 nltk-3.4.5 pytorch-transformers-1.2.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.95 seqeval-0.0.5 torch-1.2.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBcE-D7siTnm"
      },
      "source": [
        "### **Fine-Tuning:**\n",
        "> For finetuning or training the **bert-base** model run the 'run_ner.py' as command given below.\n",
        "\n",
        "> In below command we have to pass different arguments:\n",
        "   \n",
        "*   '--data_dir' argument required to collect dataset. Pass 'data/' as argument which we can see as directory inside 'BERT-NER' folder for the previous comment and command for 'BERT-NER files' .\n",
        "*   '--bert_model' used to download **pretrained bert base** model of Hugging Face transformers. There are different model-names as suggested by hugging face for argument, here we select 'bert-base-cased'.\n",
        "*   '--task_name' argument used for task to perform. Enter 'ner' as we will train the model for Named Entity Recogintion(NER).\n",
        "*   '--output_dir' argument is for where to store fine-tuned model. We give name 'out_base' for directory  where fine-tuned model stored.\n",
        "*   Other arguments like '--max_seq_length', '--num_train_epochs' and '--warmup_proportion', just give values as suggested in repository.\n",
        "*   For training pass argument '--do_train' and after that evaluating for results pass argument '--do_eval'.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLFE2bp9f7Vv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18000fbd-905e-49eb-bbad-abde917e658e"
      },
      "source": [
        "!python run_ner.py --data_dir=data/ --bert_model=bert-base-cased --task_name=ner --output_dir=out_ner --max_seq_length=128 --do_train --num_train_epochs 3 --do_eval --warmup_proportion=0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/01/2021 09:40:30 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/01/2021 09:40:31 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
            "06/01/2021 09:40:32 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
            "06/01/2021 09:40:32 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 12,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "06/01/2021 09:40:33 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
            "06/01/2021 09:40:36 - INFO - pytorch_transformers.modeling_utils -   Weights of Ner not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "06/01/2021 09:40:36 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in Ner: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   guid: train-0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   tokens: EU rejects German call to boycott British la ##mb .\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_ids: 101 7270 22961 1528 1840 1106 21423 1418 2495 12913 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   guid: train-1\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   tokens: Peter Blackburn\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_ids: 101 1943 14428 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   guid: train-2\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   tokens: BR ##US ##SE ##LS 1996 - 08 - 22\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_ids: 101 26660 13329 12649 15928 1820 118 4775 118 1659 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   guid: train-3\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   tokens: The European Commission said on Thursday it disagreed with German advice to consumers to s ##hun British la ##mb until scientists determine whether mad cow disease can be transmitted to sheep .\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_ids: 101 1109 1735 2827 1163 1113 9170 1122 19786 1114 1528 5566 1106 11060 1106 188 17315 1418 2495 12913 1235 6479 4959 2480 6340 13991 3653 1169 1129 12086 1106 8892 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   guid: train-4\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   tokens: Germany ' s representative to the European Union ' s veterinary committee Werner Z ##wing ##mann said on Wednesday consumers should buy sheep ##me ##at from countries other than Britain until the scientific advice was clearer .\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_ids: 101 1860 112 188 4702 1106 1103 1735 1913 112 188 27431 3914 14651 163 7635 4119 1163 1113 9031 11060 1431 4417 8892 3263 2980 1121 2182 1168 1190 2855 1235 1103 3812 5566 1108 27830 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 09:40:55 - INFO - __main__ -   ***** Running training *****\n",
            "06/01/2021 09:40:55 - INFO - __main__ -     Num examples = 14041\n",
            "06/01/2021 09:40:55 - INFO - __main__ -     Batch size = 32\n",
            "06/01/2021 09:40:55 - INFO - __main__ -     Num steps = 438\n",
            "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/439 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/439 [00:03<27:47,  3.81s/it]\u001b[A\n",
            "Iteration:   0% 2/439 [00:07<27:25,  3.77s/it]\u001b[A\n",
            "Iteration:   1% 3/439 [00:11<27:14,  3.75s/it]\u001b[A\n",
            "Iteration:   1% 4/439 [00:14<27:03,  3.73s/it]\u001b[A\n",
            "Iteration:   1% 5/439 [00:18<26:51,  3.71s/it]\u001b[A\n",
            "Iteration:   1% 6/439 [00:22<26:54,  3.73s/it]\u001b[A\n",
            "Iteration:   2% 7/439 [00:25<26:39,  3.70s/it]\u001b[A\n",
            "Iteration:   2% 8/439 [00:29<26:30,  3.69s/it]\u001b[A\n",
            "Iteration:   2% 9/439 [00:33<26:25,  3.69s/it]\u001b[A\n",
            "Iteration:   2% 10/439 [00:36<26:21,  3.69s/it]\u001b[A\n",
            "Iteration:   3% 11/439 [00:40<26:21,  3.69s/it]\u001b[A\n",
            "Iteration:   3% 12/439 [00:44<26:20,  3.70s/it]\u001b[A\n",
            "Iteration:   3% 13/439 [00:48<26:20,  3.71s/it]\u001b[A\n",
            "Iteration:   3% 14/439 [00:51<26:10,  3.70s/it]\u001b[A\n",
            "Iteration:   3% 15/439 [00:55<26:01,  3.68s/it]\u001b[A\n",
            "Iteration:   4% 16/439 [00:59<25:57,  3.68s/it]\u001b[A\n",
            "Iteration:   4% 17/439 [01:02<25:57,  3.69s/it]\u001b[A\n",
            "Iteration:   4% 18/439 [01:06<25:51,  3.68s/it]\u001b[A\n",
            "Iteration:   4% 19/439 [01:10<25:42,  3.67s/it]\u001b[A\n",
            "Iteration:   5% 20/439 [01:13<25:39,  3.67s/it]\u001b[A\n",
            "Iteration:   5% 21/439 [01:17<25:36,  3.68s/it]\u001b[A\n",
            "Iteration:   5% 22/439 [01:21<25:36,  3.68s/it]\u001b[A\n",
            "Iteration:   5% 23/439 [01:24<25:33,  3.69s/it]\u001b[A\n",
            "Iteration:   5% 24/439 [01:28<25:31,  3.69s/it]\u001b[A\n",
            "Iteration:   6% 25/439 [01:32<25:31,  3.70s/it]\u001b[A\n",
            "Iteration:   6% 26/439 [01:36<25:25,  3.69s/it]\u001b[A\n",
            "Iteration:   6% 27/439 [01:39<25:27,  3.71s/it]\u001b[A\n",
            "Iteration:   6% 28/439 [01:43<25:23,  3.71s/it]\u001b[A\n",
            "Iteration:   7% 29/439 [01:47<25:19,  3.71s/it]\u001b[A\n",
            "Iteration:   7% 30/439 [01:50<25:16,  3.71s/it]\u001b[A\n",
            "Iteration:   7% 31/439 [01:54<25:13,  3.71s/it]\u001b[A\n",
            "Iteration:   7% 32/439 [01:58<25:07,  3.70s/it]\u001b[A\n",
            "Iteration:   8% 33/439 [02:01<24:58,  3.69s/it]\u001b[A\n",
            "Iteration:   8% 34/439 [02:05<24:58,  3.70s/it]\u001b[A\n",
            "Iteration:   8% 35/439 [02:09<24:57,  3.71s/it]\u001b[A\n",
            "Iteration:   8% 36/439 [02:13<24:56,  3.71s/it]\u001b[A\n",
            "Iteration:   8% 37/439 [02:16<24:50,  3.71s/it]\u001b[A\n",
            "Iteration:   9% 38/439 [02:20<24:45,  3.70s/it]\u001b[A\n",
            "Iteration:   9% 39/439 [02:24<24:44,  3.71s/it]\u001b[A\n",
            "Iteration:   9% 40/439 [02:27<24:40,  3.71s/it]\u001b[A\n",
            "Iteration:   9% 41/439 [02:31<24:34,  3.71s/it]\u001b[A\n",
            "Iteration:  10% 42/439 [02:35<24:24,  3.69s/it]\u001b[A\n",
            "Iteration:  10% 43/439 [02:38<24:20,  3.69s/it]\u001b[A\n",
            "Iteration:  10% 44/439 [02:42<24:15,  3.68s/it]\u001b[A\n",
            "Iteration:  10% 45/439 [02:46<24:13,  3.69s/it]\u001b[A\n",
            "Iteration:  10% 46/439 [02:50<24:09,  3.69s/it]\u001b[A\n",
            "Iteration:  11% 47/439 [02:53<24:04,  3.68s/it]\u001b[A\n",
            "Iteration:  11% 48/439 [02:57<24:11,  3.71s/it]\u001b[A\n",
            "Iteration:  11% 49/439 [03:01<24:06,  3.71s/it]\u001b[A\n",
            "Iteration:  11% 50/439 [03:04<24:00,  3.70s/it]\u001b[A\n",
            "Iteration:  12% 51/439 [03:08<23:53,  3.69s/it]\u001b[A\n",
            "Iteration:  12% 52/439 [03:12<23:49,  3.69s/it]\u001b[A\n",
            "Iteration:  12% 53/439 [03:15<23:47,  3.70s/it]\u001b[A\n",
            "Iteration:  12% 54/439 [03:19<23:46,  3.70s/it]\u001b[A\n",
            "Iteration:  13% 55/439 [03:23<23:53,  3.73s/it]\u001b[A\n",
            "Iteration:  13% 56/439 [03:27<23:49,  3.73s/it]\u001b[A\n",
            "Iteration:  13% 57/439 [03:30<23:40,  3.72s/it]\u001b[A\n",
            "Iteration:  13% 58/439 [03:34<23:30,  3.70s/it]\u001b[A\n",
            "Iteration:  13% 59/439 [03:38<23:23,  3.69s/it]\u001b[A\n",
            "Iteration:  14% 60/439 [03:41<23:21,  3.70s/it]\u001b[A\n",
            "Iteration:  14% 61/439 [03:45<23:18,  3.70s/it]\u001b[A\n",
            "Iteration:  14% 62/439 [03:49<23:24,  3.73s/it]\u001b[A\n",
            "Iteration:  14% 63/439 [03:53<23:19,  3.72s/it]\u001b[A\n",
            "Iteration:  15% 64/439 [03:56<23:15,  3.72s/it]\u001b[A\n",
            "Iteration:  15% 65/439 [04:00<23:06,  3.71s/it]\u001b[A\n",
            "Iteration:  15% 66/439 [04:04<22:57,  3.69s/it]\u001b[A\n",
            "Iteration:  15% 67/439 [04:07<22:53,  3.69s/it]\u001b[A\n",
            "Iteration:  15% 68/439 [04:11<22:53,  3.70s/it]\u001b[A\n",
            "Iteration:  16% 69/439 [04:15<22:59,  3.73s/it]\u001b[A\n",
            "Iteration:  16% 70/439 [04:19<22:48,  3.71s/it]\u001b[A\n",
            "Iteration:  16% 71/439 [04:22<22:41,  3.70s/it]\u001b[A\n",
            "Iteration:  16% 72/439 [04:26<22:36,  3.70s/it]\u001b[A\n",
            "Iteration:  17% 73/439 [04:30<22:36,  3.71s/it]\u001b[A\n",
            "Iteration:  17% 74/439 [04:33<22:32,  3.71s/it]\u001b[A\n",
            "Iteration:  17% 75/439 [04:37<22:23,  3.69s/it]\u001b[A\n",
            "Iteration:  17% 76/439 [04:41<22:30,  3.72s/it]\u001b[A\n",
            "Iteration:  18% 77/439 [04:45<22:24,  3.72s/it]\u001b[A\n",
            "Iteration:  18% 78/439 [04:48<22:19,  3.71s/it]\u001b[A\n",
            "Iteration:  18% 79/439 [04:52<22:16,  3.71s/it]\u001b[A\n",
            "Iteration:  18% 80/439 [04:56<22:11,  3.71s/it]\u001b[A\n",
            "Iteration:  18% 81/439 [04:59<22:02,  3.70s/it]\u001b[A\n",
            "Iteration:  19% 82/439 [05:03<21:56,  3.69s/it]\u001b[A\n",
            "Iteration:  19% 83/439 [05:07<22:07,  3.73s/it]\u001b[A\n",
            "Iteration:  19% 84/439 [05:10<21:58,  3.71s/it]\u001b[A\n",
            "Iteration:  19% 85/439 [05:14<21:50,  3.70s/it]\u001b[A\n",
            "Iteration:  20% 86/439 [05:18<21:45,  3.70s/it]\u001b[A\n",
            "Iteration:  20% 87/439 [05:22<21:45,  3.71s/it]\u001b[A\n",
            "Iteration:  20% 88/439 [05:25<21:37,  3.70s/it]\u001b[A\n",
            "Iteration:  20% 89/439 [05:29<21:32,  3.69s/it]\u001b[A\n",
            "Iteration:  21% 90/439 [05:33<21:32,  3.70s/it]\u001b[A\n",
            "Iteration:  21% 91/439 [05:36<21:24,  3.69s/it]\u001b[A\n",
            "Iteration:  21% 92/439 [05:40<21:21,  3.69s/it]\u001b[A\n",
            "Iteration:  21% 93/439 [05:44<21:19,  3.70s/it]\u001b[A\n",
            "Iteration:  21% 94/439 [05:47<21:12,  3.69s/it]\u001b[A\n",
            "Iteration:  22% 95/439 [05:51<21:07,  3.69s/it]\u001b[A\n",
            "Iteration:  22% 96/439 [05:55<21:05,  3.69s/it]\u001b[A\n",
            "Iteration:  22% 97/439 [05:58<21:03,  3.69s/it]\u001b[A\n",
            "Iteration:  22% 98/439 [06:02<21:01,  3.70s/it]\u001b[A\n",
            "Iteration:  23% 99/439 [06:06<20:57,  3.70s/it]\u001b[A\n",
            "Iteration:  23% 100/439 [06:10<20:51,  3.69s/it]\u001b[A\n",
            "Iteration:  23% 101/439 [06:13<20:47,  3.69s/it]\u001b[A\n",
            "Iteration:  23% 102/439 [06:17<20:46,  3.70s/it]\u001b[A\n",
            "Iteration:  23% 103/439 [06:21<20:45,  3.71s/it]\u001b[A\n",
            "Iteration:  24% 104/439 [06:24<20:44,  3.71s/it]\u001b[A\n",
            "Iteration:  24% 105/439 [06:28<20:36,  3.70s/it]\u001b[A\n",
            "Iteration:  24% 106/439 [06:32<20:29,  3.69s/it]\u001b[A\n",
            "Iteration:  24% 107/439 [06:35<20:23,  3.69s/it]\u001b[A\n",
            "Iteration:  25% 108/439 [06:39<20:19,  3.68s/it]\u001b[A\n",
            "Iteration:  25% 109/439 [06:43<20:24,  3.71s/it]\u001b[A\n",
            "Iteration:  25% 110/439 [06:47<20:19,  3.71s/it]\u001b[A\n",
            "Iteration:  25% 111/439 [06:50<20:16,  3.71s/it]\u001b[A\n",
            "Iteration:  26% 112/439 [06:54<20:10,  3.70s/it]\u001b[A\n",
            "Iteration:  26% 113/439 [06:58<20:11,  3.72s/it]\u001b[A\n",
            "Iteration:  26% 114/439 [07:01<20:07,  3.72s/it]\u001b[A\n",
            "Iteration:  26% 115/439 [07:05<20:03,  3.71s/it]\u001b[A\n",
            "Iteration:  26% 116/439 [07:09<20:06,  3.74s/it]\u001b[A\n",
            "Iteration:  27% 117/439 [07:13<19:56,  3.72s/it]\u001b[A\n",
            "Iteration:  27% 118/439 [07:16<19:53,  3.72s/it]\u001b[A\n",
            "Iteration:  27% 119/439 [07:20<19:52,  3.73s/it]\u001b[A\n",
            "Iteration:  27% 120/439 [07:24<19:46,  3.72s/it]\u001b[A\n",
            "Iteration:  28% 121/439 [07:27<19:37,  3.70s/it]\u001b[A\n",
            "Iteration:  28% 122/439 [07:31<19:30,  3.69s/it]\u001b[A\n",
            "Iteration:  28% 123/439 [07:35<19:35,  3.72s/it]\u001b[A\n",
            "Iteration:  28% 124/439 [07:39<19:28,  3.71s/it]\u001b[A\n",
            "Iteration:  28% 125/439 [07:42<19:23,  3.70s/it]\u001b[A\n",
            "Iteration:  29% 126/439 [07:46<19:19,  3.70s/it]\u001b[A\n",
            "Iteration:  29% 127/439 [07:50<19:17,  3.71s/it]\u001b[A\n",
            "Iteration:  29% 128/439 [07:53<19:12,  3.71s/it]\u001b[A\n",
            "Iteration:  29% 129/439 [07:57<19:03,  3.69s/it]\u001b[A\n",
            "Iteration:  30% 130/439 [08:01<18:56,  3.68s/it]\u001b[A\n",
            "Iteration:  30% 131/439 [08:05<19:05,  3.72s/it]\u001b[A\n",
            "Iteration:  30% 132/439 [08:08<18:56,  3.70s/it]\u001b[A\n",
            "Iteration:  30% 133/439 [08:12<18:55,  3.71s/it]\u001b[A\n",
            "Iteration:  31% 134/439 [08:16<18:49,  3.70s/it]\u001b[A\n",
            "Iteration:  31% 135/439 [08:19<18:42,  3.69s/it]\u001b[A\n",
            "Iteration:  31% 136/439 [08:23<18:39,  3.69s/it]\u001b[A\n",
            "Iteration:  31% 137/439 [08:27<18:48,  3.74s/it]\u001b[A\n",
            "Iteration:  31% 138/439 [08:31<18:43,  3.73s/it]\u001b[A\n",
            "Iteration:  32% 139/439 [08:34<18:33,  3.71s/it]\u001b[A\n",
            "Iteration:  32% 140/439 [08:38<18:28,  3.71s/it]\u001b[A\n",
            "Iteration:  32% 141/439 [08:42<18:26,  3.71s/it]\u001b[A\n",
            "Iteration:  32% 142/439 [08:45<18:19,  3.70s/it]\u001b[A\n",
            "Iteration:  33% 143/439 [08:49<18:16,  3.70s/it]\u001b[A\n",
            "Iteration:  33% 144/439 [08:53<18:09,  3.69s/it]\u001b[A\n",
            "Iteration:  33% 145/439 [08:56<18:08,  3.70s/it]\u001b[A\n",
            "Iteration:  33% 146/439 [09:00<18:01,  3.69s/it]\u001b[A\n",
            "Iteration:  33% 147/439 [09:04<17:59,  3.70s/it]\u001b[A\n",
            "Iteration:  34% 148/439 [09:07<17:53,  3.69s/it]\u001b[A\n",
            "Iteration:  34% 149/439 [09:11<17:52,  3.70s/it]\u001b[A\n",
            "Iteration:  34% 150/439 [09:15<17:50,  3.70s/it]\u001b[A\n",
            "Iteration:  34% 151/439 [09:19<17:44,  3.70s/it]\u001b[A\n",
            "Iteration:  35% 152/439 [09:22<17:40,  3.69s/it]\u001b[A\n",
            "Iteration:  35% 153/439 [09:26<17:37,  3.70s/it]\u001b[A\n",
            "Iteration:  35% 154/439 [09:30<17:32,  3.69s/it]\u001b[A\n",
            "Iteration:  35% 155/439 [09:33<17:30,  3.70s/it]\u001b[A\n",
            "Iteration:  36% 156/439 [09:37<17:21,  3.68s/it]\u001b[A\n",
            "Iteration:  36% 157/439 [09:41<17:18,  3.68s/it]\u001b[A\n",
            "Iteration:  36% 158/439 [09:44<17:17,  3.69s/it]\u001b[A\n",
            "Iteration:  36% 159/439 [09:48<17:15,  3.70s/it]\u001b[A\n",
            "Iteration:  36% 160/439 [09:52<17:11,  3.70s/it]\u001b[A\n",
            "Iteration:  37% 161/439 [09:55<17:07,  3.69s/it]\u001b[A\n",
            "Iteration:  37% 162/439 [09:59<17:04,  3.70s/it]\u001b[A\n",
            "Iteration:  37% 163/439 [10:03<17:03,  3.71s/it]\u001b[A\n",
            "Iteration:  37% 164/439 [10:07<17:00,  3.71s/it]\u001b[A\n",
            "Iteration:  38% 165/439 [10:10<16:58,  3.72s/it]\u001b[A\n",
            "Iteration:  38% 166/439 [10:14<16:51,  3.71s/it]\u001b[A\n",
            "Iteration:  38% 167/439 [10:18<16:48,  3.71s/it]\u001b[A\n",
            "Iteration:  38% 168/439 [10:21<16:43,  3.70s/it]\u001b[A\n",
            "Iteration:  38% 169/439 [10:25<16:41,  3.71s/it]\u001b[A\n",
            "Iteration:  39% 170/439 [10:29<16:38,  3.71s/it]\u001b[A\n",
            "Iteration:  39% 171/439 [10:33<16:32,  3.70s/it]\u001b[A\n",
            "Iteration:  39% 172/439 [10:36<16:26,  3.70s/it]\u001b[A\n",
            "Iteration:  39% 173/439 [10:40<16:22,  3.69s/it]\u001b[A\n",
            "Iteration:  40% 174/439 [10:44<16:22,  3.71s/it]\u001b[A\n",
            "Iteration:  40% 175/439 [10:47<16:18,  3.71s/it]\u001b[A\n",
            "Iteration:  40% 176/439 [10:51<16:15,  3.71s/it]\u001b[A\n",
            "Iteration:  40% 177/439 [10:55<16:09,  3.70s/it]\u001b[A\n",
            "Iteration:  41% 178/439 [10:58<16:06,  3.70s/it]\u001b[A\n",
            "Iteration:  41% 179/439 [11:02<16:01,  3.70s/it]\u001b[A\n",
            "Iteration:  41% 180/439 [11:06<15:58,  3.70s/it]\u001b[A\n",
            "Iteration:  41% 181/439 [11:10<15:53,  3.70s/it]\u001b[A\n",
            "Iteration:  41% 182/439 [11:13<15:46,  3.68s/it]\u001b[A\n",
            "Iteration:  42% 183/439 [11:17<15:42,  3.68s/it]\u001b[A\n",
            "Iteration:  42% 184/439 [11:21<15:42,  3.70s/it]\u001b[A\n",
            "Iteration:  42% 185/439 [11:24<15:37,  3.69s/it]\u001b[A\n",
            "Iteration:  42% 186/439 [11:28<15:34,  3.69s/it]\u001b[A\n",
            "Iteration:  43% 187/439 [11:32<15:31,  3.70s/it]\u001b[A\n",
            "Iteration:  43% 188/439 [11:35<15:32,  3.72s/it]\u001b[A\n",
            "Iteration:  43% 189/439 [11:39<15:22,  3.69s/it]\u001b[A\n",
            "Iteration:  43% 190/439 [11:43<15:15,  3.68s/it]\u001b[A\n",
            "Iteration:  44% 191/439 [11:46<15:12,  3.68s/it]\u001b[A\n",
            "Iteration:  44% 192/439 [11:50<15:10,  3.69s/it]\u001b[A\n",
            "Iteration:  44% 193/439 [11:54<15:07,  3.69s/it]\u001b[A\n",
            "Iteration:  44% 194/439 [11:58<15:03,  3.69s/it]\u001b[A\n",
            "Iteration:  44% 195/439 [12:01<15:01,  3.70s/it]\u001b[A\n",
            "Iteration:  45% 196/439 [12:05<14:56,  3.69s/it]\u001b[A\n",
            "Iteration:  45% 197/439 [12:09<14:50,  3.68s/it]\u001b[A\n",
            "Iteration:  45% 198/439 [12:12<14:46,  3.68s/it]\u001b[A\n",
            "Iteration:  45% 199/439 [12:16<14:41,  3.67s/it]\u001b[A\n",
            "Iteration:  46% 200/439 [12:20<14:37,  3.67s/it]\u001b[A\n",
            "Iteration:  46% 201/439 [12:23<14:33,  3.67s/it]\u001b[A\n",
            "Iteration:  46% 202/439 [12:27<14:29,  3.67s/it]\u001b[A\n",
            "Iteration:  46% 203/439 [12:31<14:29,  3.68s/it]\u001b[A\n",
            "Iteration:  46% 204/439 [12:34<14:32,  3.71s/it]\u001b[A\n",
            "Iteration:  47% 205/439 [12:38<14:26,  3.70s/it]\u001b[A\n",
            "Iteration:  47% 206/439 [12:42<14:33,  3.75s/it]\u001b[A\n",
            "Iteration:  47% 207/439 [12:46<14:24,  3.73s/it]\u001b[A\n",
            "Iteration:  47% 208/439 [12:49<14:19,  3.72s/it]\u001b[A\n",
            "Iteration:  48% 209/439 [12:53<14:15,  3.72s/it]\u001b[A\n",
            "Iteration:  48% 210/439 [12:57<14:07,  3.70s/it]\u001b[A\n",
            "Iteration:  48% 211/439 [13:00<13:59,  3.68s/it]\u001b[A\n",
            "Iteration:  48% 212/439 [13:04<13:57,  3.69s/it]\u001b[A\n",
            "Iteration:  49% 213/439 [13:08<13:52,  3.68s/it]\u001b[A\n",
            "Iteration:  49% 214/439 [13:11<13:52,  3.70s/it]\u001b[A\n",
            "Iteration:  49% 215/439 [13:15<13:51,  3.71s/it]\u001b[A\n",
            "Iteration:  49% 216/439 [13:19<13:48,  3.72s/it]\u001b[A\n",
            "Iteration:  49% 217/439 [13:23<13:44,  3.71s/it]\u001b[A\n",
            "Iteration:  50% 218/439 [13:26<13:41,  3.72s/it]\u001b[A\n",
            "Iteration:  50% 219/439 [13:30<13:37,  3.72s/it]\u001b[A\n",
            "Iteration:  50% 220/439 [13:34<13:36,  3.73s/it]\u001b[A\n",
            "Iteration:  50% 221/439 [13:37<13:30,  3.72s/it]\u001b[A\n",
            "Iteration:  51% 222/439 [13:41<13:24,  3.71s/it]\u001b[A\n",
            "Iteration:  51% 223/439 [13:45<13:22,  3.71s/it]\u001b[A\n",
            "Iteration:  51% 224/439 [13:49<13:21,  3.73s/it]\u001b[A\n",
            "Iteration:  51% 225/439 [13:52<13:17,  3.73s/it]\u001b[A\n",
            "Iteration:  51% 226/439 [13:56<13:09,  3.71s/it]\u001b[A\n",
            "Iteration:  52% 227/439 [14:00<13:04,  3.70s/it]\u001b[A\n",
            "Iteration:  52% 228/439 [14:03<12:59,  3.69s/it]\u001b[A\n",
            "Iteration:  52% 229/439 [14:07<12:53,  3.69s/it]\u001b[A\n",
            "Iteration:  52% 230/439 [14:11<12:48,  3.68s/it]\u001b[A\n",
            "Iteration:  53% 231/439 [14:14<12:44,  3.67s/it]\u001b[A\n",
            "Iteration:  53% 232/439 [14:18<12:40,  3.67s/it]\u001b[A\n",
            "Iteration:  53% 233/439 [14:22<12:38,  3.68s/it]\u001b[A\n",
            "Iteration:  53% 234/439 [14:25<12:34,  3.68s/it]\u001b[A\n",
            "Iteration:  54% 235/439 [14:29<12:32,  3.69s/it]\u001b[A\n",
            "Iteration:  54% 236/439 [14:33<12:28,  3.69s/it]\u001b[A\n",
            "Iteration:  54% 237/439 [14:37<12:28,  3.70s/it]\u001b[A\n",
            "Iteration:  54% 238/439 [14:40<12:26,  3.71s/it]\u001b[A\n",
            "Iteration:  54% 239/439 [14:44<12:23,  3.72s/it]\u001b[A\n",
            "Iteration:  55% 240/439 [14:48<12:19,  3.72s/it]\u001b[A\n",
            "Iteration:  55% 241/439 [14:51<12:13,  3.71s/it]\u001b[A\n",
            "Iteration:  55% 242/439 [14:55<12:10,  3.71s/it]\u001b[A\n",
            "Iteration:  55% 243/439 [14:59<12:04,  3.70s/it]\u001b[A\n",
            "Iteration:  56% 244/439 [15:02<11:57,  3.68s/it]\u001b[A\n",
            "Iteration:  56% 245/439 [15:06<11:55,  3.69s/it]\u001b[A\n",
            "Iteration:  56% 246/439 [15:10<11:54,  3.70s/it]\u001b[A\n",
            "Iteration:  56% 247/439 [15:14<11:48,  3.69s/it]\u001b[A\n",
            "Iteration:  56% 248/439 [15:17<11:46,  3.70s/it]\u001b[A\n",
            "Iteration:  57% 249/439 [15:21<11:42,  3.70s/it]\u001b[A\n",
            "Iteration:  57% 250/439 [15:25<11:36,  3.69s/it]\u001b[A\n",
            "Iteration:  57% 251/439 [15:28<11:32,  3.68s/it]\u001b[A\n",
            "Iteration:  57% 252/439 [15:32<11:29,  3.68s/it]\u001b[A\n",
            "Iteration:  58% 253/439 [15:36<11:24,  3.68s/it]\u001b[A\n",
            "Iteration:  58% 254/439 [15:39<11:24,  3.70s/it]\u001b[A\n",
            "Iteration:  58% 255/439 [15:43<11:20,  3.70s/it]\u001b[A\n",
            "Iteration:  58% 256/439 [15:47<11:14,  3.69s/it]\u001b[A\n",
            "Iteration:  59% 257/439 [15:51<11:13,  3.70s/it]\u001b[A\n",
            "Iteration:  59% 258/439 [15:54<11:09,  3.70s/it]\u001b[A\n",
            "Iteration:  59% 259/439 [15:58<11:05,  3.70s/it]\u001b[A\n",
            "Iteration:  59% 260/439 [16:02<11:01,  3.70s/it]\u001b[A\n",
            "Iteration:  59% 261/439 [16:05<11:00,  3.71s/it]\u001b[A\n",
            "Iteration:  60% 262/439 [16:09<10:54,  3.70s/it]\u001b[A\n",
            "Iteration:  60% 263/439 [16:13<10:50,  3.70s/it]\u001b[A\n",
            "Iteration:  60% 264/439 [16:16<10:45,  3.69s/it]\u001b[A\n",
            "Iteration:  60% 265/439 [16:20<10:42,  3.70s/it]\u001b[A\n",
            "Iteration:  61% 266/439 [16:24<10:38,  3.69s/it]\u001b[A\n",
            "Iteration:  61% 267/439 [16:27<10:36,  3.70s/it]\u001b[A\n",
            "Iteration:  61% 268/439 [16:31<10:33,  3.71s/it]\u001b[A\n",
            "Iteration:  61% 269/439 [16:35<10:30,  3.71s/it]\u001b[A\n",
            "Iteration:  62% 270/439 [16:39<10:24,  3.70s/it]\u001b[A\n",
            "Iteration:  62% 271/439 [16:42<10:27,  3.73s/it]\u001b[A\n",
            "Iteration:  62% 272/439 [16:46<10:23,  3.73s/it]\u001b[A\n",
            "Iteration:  62% 273/439 [16:50<10:18,  3.73s/it]\u001b[A\n",
            "Iteration:  62% 274/439 [16:54<10:13,  3.72s/it]\u001b[A\n",
            "Iteration:  63% 275/439 [16:57<10:07,  3.71s/it]\u001b[A\n",
            "Iteration:  63% 276/439 [17:01<10:03,  3.70s/it]\u001b[A\n",
            "Iteration:  63% 277/439 [17:05<09:58,  3.69s/it]\u001b[A\n",
            "Iteration:  63% 278/439 [17:08<09:53,  3.68s/it]\u001b[A\n",
            "Iteration:  64% 279/439 [17:12<09:49,  3.68s/it]\u001b[A\n",
            "Iteration:  64% 280/439 [17:16<09:46,  3.69s/it]\u001b[A\n",
            "Iteration:  64% 281/439 [17:19<09:43,  3.70s/it]\u001b[A\n",
            "Iteration:  64% 282/439 [17:23<09:39,  3.69s/it]\u001b[A\n",
            "Iteration:  64% 283/439 [17:27<09:36,  3.69s/it]\u001b[A\n",
            "Iteration:  65% 284/439 [17:30<09:32,  3.69s/it]\u001b[A\n",
            "Iteration:  65% 285/439 [17:34<09:28,  3.69s/it]\u001b[A\n",
            "Iteration:  65% 286/439 [17:38<09:23,  3.68s/it]\u001b[A\n",
            "Iteration:  65% 287/439 [17:41<09:21,  3.69s/it]\u001b[A\n",
            "Iteration:  66% 288/439 [17:45<09:18,  3.70s/it]\u001b[A\n",
            "Iteration:  66% 289/439 [17:49<09:15,  3.70s/it]\u001b[A\n",
            "Iteration:  66% 290/439 [17:53<09:11,  3.70s/it]\u001b[A\n",
            "Iteration:  66% 291/439 [17:56<09:06,  3.70s/it]\u001b[A\n",
            "Iteration:  67% 292/439 [18:00<09:01,  3.69s/it]\u001b[A\n",
            "Iteration:  67% 293/439 [18:04<08:58,  3.69s/it]\u001b[A\n",
            "Iteration:  67% 294/439 [18:07<08:55,  3.69s/it]\u001b[A\n",
            "Iteration:  67% 295/439 [18:11<08:51,  3.69s/it]\u001b[A\n",
            "Iteration:  67% 296/439 [18:15<08:48,  3.70s/it]\u001b[A\n",
            "Iteration:  68% 297/439 [18:19<08:48,  3.72s/it]\u001b[A\n",
            "Iteration:  68% 298/439 [18:22<08:43,  3.72s/it]\u001b[A\n",
            "Iteration:  68% 299/439 [18:26<08:38,  3.71s/it]\u001b[A\n",
            "Iteration:  68% 300/439 [18:30<08:36,  3.72s/it]\u001b[A\n",
            "Iteration:  69% 301/439 [18:33<08:30,  3.70s/it]\u001b[A\n",
            "Iteration:  69% 302/439 [18:37<08:25,  3.69s/it]\u001b[A\n",
            "Iteration:  69% 303/439 [18:41<08:22,  3.69s/it]\u001b[A\n",
            "Iteration:  69% 304/439 [18:45<08:24,  3.73s/it]\u001b[A\n",
            "Iteration:  69% 305/439 [18:48<08:19,  3.73s/it]\u001b[A\n",
            "Iteration:  70% 306/439 [18:52<08:15,  3.72s/it]\u001b[A\n",
            "Iteration:  70% 307/439 [18:56<08:10,  3.72s/it]\u001b[A\n",
            "Iteration:  70% 308/439 [18:59<08:05,  3.70s/it]\u001b[A\n",
            "Iteration:  70% 309/439 [19:03<08:00,  3.69s/it]\u001b[A\n",
            "Iteration:  71% 310/439 [19:07<07:56,  3.69s/it]\u001b[A\n",
            "Iteration:  71% 311/439 [19:10<07:53,  3.70s/it]\u001b[A\n",
            "Iteration:  71% 312/439 [19:14<07:49,  3.70s/it]\u001b[A\n",
            "Iteration:  71% 313/439 [19:18<07:47,  3.71s/it]\u001b[A\n",
            "Iteration:  72% 314/439 [19:22<07:42,  3.70s/it]\u001b[A\n",
            "Iteration:  72% 315/439 [19:25<07:37,  3.69s/it]\u001b[A\n",
            "Iteration:  72% 316/439 [19:29<07:33,  3.69s/it]\u001b[A\n",
            "Iteration:  72% 317/439 [19:33<07:30,  3.69s/it]\u001b[A\n",
            "Iteration:  72% 318/439 [19:36<07:29,  3.71s/it]\u001b[A\n",
            "Iteration:  73% 319/439 [19:40<07:24,  3.71s/it]\u001b[A\n",
            "Iteration:  73% 320/439 [19:44<07:20,  3.70s/it]\u001b[A\n",
            "Iteration:  73% 321/439 [19:47<07:16,  3.70s/it]\u001b[A\n",
            "Iteration:  73% 322/439 [19:51<07:12,  3.69s/it]\u001b[A\n",
            "Iteration:  74% 323/439 [19:55<07:08,  3.70s/it]\u001b[A\n",
            "Iteration:  74% 324/439 [19:58<07:04,  3.69s/it]\u001b[A\n",
            "Iteration:  74% 325/439 [20:02<07:01,  3.70s/it]\u001b[A\n",
            "Iteration:  74% 326/439 [20:06<06:56,  3.69s/it]\u001b[A\n",
            "Iteration:  74% 327/439 [20:10<06:54,  3.70s/it]\u001b[A\n",
            "Iteration:  75% 328/439 [20:13<06:49,  3.69s/it]\u001b[A\n",
            "Iteration:  75% 329/439 [20:17<06:44,  3.68s/it]\u001b[A\n",
            "Iteration:  75% 330/439 [20:21<06:42,  3.69s/it]\u001b[A\n",
            "Iteration:  75% 331/439 [20:24<06:37,  3.68s/it]\u001b[A\n",
            "Iteration:  76% 332/439 [20:28<06:34,  3.69s/it]\u001b[A\n",
            "Iteration:  76% 333/439 [20:32<06:32,  3.70s/it]\u001b[A\n",
            "Iteration:  76% 334/439 [20:35<06:28,  3.70s/it]\u001b[A\n",
            "Iteration:  76% 335/439 [20:39<06:23,  3.69s/it]\u001b[A\n",
            "Iteration:  77% 336/439 [20:43<06:20,  3.69s/it]\u001b[A\n",
            "Iteration:  77% 337/439 [20:47<06:20,  3.73s/it]\u001b[A\n",
            "Iteration:  77% 338/439 [20:50<06:15,  3.72s/it]\u001b[A\n",
            "Iteration:  77% 339/439 [20:54<06:12,  3.72s/it]\u001b[A\n",
            "Iteration:  77% 340/439 [20:58<06:07,  3.71s/it]\u001b[A\n",
            "Iteration:  78% 341/439 [21:01<06:04,  3.72s/it]\u001b[A\n",
            "Iteration:  78% 342/439 [21:05<06:00,  3.71s/it]\u001b[A\n",
            "Iteration:  78% 343/439 [21:09<05:55,  3.70s/it]\u001b[A\n",
            "Iteration:  78% 344/439 [21:13<05:54,  3.73s/it]\u001b[A\n",
            "Iteration:  79% 345/439 [21:16<05:49,  3.72s/it]\u001b[A\n",
            "Iteration:  79% 346/439 [21:20<05:45,  3.71s/it]\u001b[A\n",
            "Iteration:  79% 347/439 [21:24<05:42,  3.72s/it]\u001b[A\n",
            "Iteration:  79% 348/439 [21:27<05:38,  3.72s/it]\u001b[A\n",
            "Iteration:  79% 349/439 [21:31<05:33,  3.71s/it]\u001b[A\n",
            "Iteration:  80% 350/439 [21:35<05:28,  3.70s/it]\u001b[A\n",
            "Iteration:  80% 351/439 [21:39<05:28,  3.74s/it]\u001b[A\n",
            "Iteration:  80% 352/439 [21:42<05:24,  3.73s/it]\u001b[A\n",
            "Iteration:  80% 353/439 [21:46<05:19,  3.72s/it]\u001b[A\n",
            "Iteration:  81% 354/439 [21:50<05:15,  3.71s/it]\u001b[A\n",
            "Iteration:  81% 355/439 [21:53<05:11,  3.71s/it]\u001b[A\n",
            "Iteration:  81% 356/439 [21:57<05:08,  3.71s/it]\u001b[A\n",
            "Iteration:  81% 357/439 [22:01<05:03,  3.70s/it]\u001b[A\n",
            "Iteration:  82% 358/439 [22:05<05:00,  3.71s/it]\u001b[A\n",
            "Iteration:  82% 359/439 [22:08<04:56,  3.70s/it]\u001b[A\n",
            "Iteration:  82% 360/439 [22:12<04:51,  3.69s/it]\u001b[A\n",
            "Iteration:  82% 361/439 [22:16<04:48,  3.70s/it]\u001b[A\n",
            "Iteration:  82% 362/439 [22:19<04:44,  3.70s/it]\u001b[A\n",
            "Iteration:  83% 363/439 [22:23<04:39,  3.68s/it]\u001b[A\n",
            "Iteration:  83% 364/439 [22:27<04:35,  3.68s/it]\u001b[A\n",
            "Iteration:  83% 365/439 [22:30<04:34,  3.72s/it]\u001b[A\n",
            "Iteration:  83% 366/439 [22:34<04:31,  3.71s/it]\u001b[A\n",
            "Iteration:  84% 367/439 [22:38<04:27,  3.71s/it]\u001b[A\n",
            "Iteration:  84% 368/439 [22:42<04:22,  3.70s/it]\u001b[A\n",
            "Iteration:  84% 369/439 [22:45<04:19,  3.70s/it]\u001b[A\n",
            "Iteration:  84% 370/439 [22:49<04:15,  3.70s/it]\u001b[A\n",
            "Iteration:  85% 371/439 [22:53<04:11,  3.70s/it]\u001b[A\n",
            "Iteration:  85% 372/439 [22:56<04:08,  3.71s/it]\u001b[A\n",
            "Iteration:  85% 373/439 [23:00<04:04,  3.71s/it]\u001b[A\n",
            "Iteration:  85% 374/439 [23:04<04:00,  3.70s/it]\u001b[A\n",
            "Iteration:  85% 375/439 [23:07<03:56,  3.69s/it]\u001b[A\n",
            "Iteration:  86% 376/439 [23:11<03:52,  3.70s/it]\u001b[A\n",
            "Iteration:  86% 377/439 [23:15<03:48,  3.69s/it]\u001b[A\n",
            "Iteration:  86% 378/439 [23:19<03:45,  3.70s/it]\u001b[A\n",
            "Iteration:  86% 379/439 [23:22<03:42,  3.71s/it]\u001b[A\n",
            "Iteration:  87% 380/439 [23:26<03:38,  3.70s/it]\u001b[A\n",
            "Iteration:  87% 381/439 [23:30<03:34,  3.69s/it]\u001b[A\n",
            "Iteration:  87% 382/439 [23:33<03:30,  3.69s/it]\u001b[A\n",
            "Iteration:  87% 383/439 [23:37<03:26,  3.68s/it]\u001b[A\n",
            "Iteration:  87% 384/439 [23:41<03:22,  3.68s/it]\u001b[A\n",
            "Iteration:  88% 385/439 [23:44<03:19,  3.70s/it]\u001b[A\n",
            "Iteration:  88% 386/439 [23:48<03:15,  3.69s/it]\u001b[A\n",
            "Iteration:  88% 387/439 [23:52<03:12,  3.69s/it]\u001b[A\n",
            "Iteration:  88% 388/439 [23:55<03:08,  3.69s/it]\u001b[A\n",
            "Iteration:  89% 389/439 [23:59<03:04,  3.69s/it]\u001b[A\n",
            "Iteration:  89% 390/439 [24:03<03:00,  3.68s/it]\u001b[A\n",
            "Iteration:  89% 391/439 [24:06<02:57,  3.69s/it]\u001b[A\n",
            "Iteration:  89% 392/439 [24:10<02:53,  3.69s/it]\u001b[A\n",
            "Iteration:  90% 393/439 [24:14<02:48,  3.67s/it]\u001b[A\n",
            "Iteration:  90% 394/439 [24:18<02:45,  3.69s/it]\u001b[A\n",
            "Iteration:  90% 395/439 [24:21<02:42,  3.68s/it]\u001b[A\n",
            "Iteration:  90% 396/439 [24:25<02:38,  3.70s/it]\u001b[A\n",
            "Iteration:  90% 397/439 [24:29<02:35,  3.70s/it]\u001b[A\n",
            "Iteration:  91% 398/439 [24:32<02:31,  3.71s/it]\u001b[A\n",
            "Iteration:  91% 399/439 [24:36<02:27,  3.70s/it]\u001b[A\n",
            "Iteration:  91% 400/439 [24:40<02:24,  3.70s/it]\u001b[A\n",
            "Iteration:  91% 401/439 [24:43<02:20,  3.71s/it]\u001b[A\n",
            "Iteration:  92% 402/439 [24:47<02:17,  3.71s/it]\u001b[A\n",
            "Iteration:  92% 403/439 [24:51<02:13,  3.70s/it]\u001b[A\n",
            "Iteration:  92% 404/439 [24:55<02:09,  3.69s/it]\u001b[A\n",
            "Iteration:  92% 405/439 [24:58<02:05,  3.69s/it]\u001b[A\n",
            "Iteration:  92% 406/439 [25:02<02:01,  3.69s/it]\u001b[A\n",
            "Iteration:  93% 407/439 [25:06<01:58,  3.70s/it]\u001b[A\n",
            "Iteration:  93% 408/439 [25:09<01:54,  3.70s/it]\u001b[A\n",
            "Iteration:  93% 409/439 [25:13<01:50,  3.69s/it]\u001b[A\n",
            "Iteration:  93% 410/439 [25:17<01:46,  3.67s/it]\u001b[A\n",
            "Iteration:  94% 411/439 [25:20<01:43,  3.71s/it]\u001b[A\n",
            "Iteration:  94% 412/439 [25:24<01:40,  3.70s/it]\u001b[A\n",
            "Iteration:  94% 413/439 [25:28<01:35,  3.69s/it]\u001b[A\n",
            "Iteration:  94% 414/439 [25:31<01:32,  3.69s/it]\u001b[A\n",
            "Iteration:  95% 415/439 [25:35<01:28,  3.70s/it]\u001b[A\n",
            "Iteration:  95% 416/439 [25:39<01:25,  3.70s/it]\u001b[A\n",
            "Iteration:  95% 417/439 [25:43<01:21,  3.71s/it]\u001b[A\n",
            "Iteration:  95% 418/439 [25:46<01:18,  3.73s/it]\u001b[A\n",
            "Iteration:  95% 419/439 [25:50<01:14,  3.71s/it]\u001b[A\n",
            "Iteration:  96% 420/439 [25:54<01:10,  3.71s/it]\u001b[A\n",
            "Iteration:  96% 421/439 [25:57<01:06,  3.70s/it]\u001b[A\n",
            "Iteration:  96% 422/439 [26:01<01:02,  3.70s/it]\u001b[A\n",
            "Iteration:  96% 423/439 [26:05<00:59,  3.70s/it]\u001b[A\n",
            "Iteration:  97% 424/439 [26:09<00:55,  3.69s/it]\u001b[A\n",
            "Iteration:  97% 425/439 [26:12<00:52,  3.72s/it]\u001b[A\n",
            "Iteration:  97% 426/439 [26:16<00:48,  3.72s/it]\u001b[A\n",
            "Iteration:  97% 427/439 [26:20<00:44,  3.72s/it]\u001b[A\n",
            "Iteration:  97% 428/439 [26:23<00:40,  3.71s/it]\u001b[A\n",
            "Iteration:  98% 429/439 [26:27<00:37,  3.72s/it]\u001b[A\n",
            "Iteration:  98% 430/439 [26:31<00:33,  3.70s/it]\u001b[A\n",
            "Iteration:  98% 431/439 [26:35<00:29,  3.71s/it]\u001b[A\n",
            "Iteration:  98% 432/439 [26:38<00:25,  3.71s/it]\u001b[A\n",
            "Iteration:  99% 433/439 [26:42<00:22,  3.71s/it]\u001b[A\n",
            "Iteration:  99% 434/439 [26:46<00:18,  3.69s/it]\u001b[A\n",
            "Iteration:  99% 435/439 [26:49<00:14,  3.69s/it]\u001b[A\n",
            "Iteration:  99% 436/439 [26:53<00:11,  3.69s/it]\u001b[A\n",
            "Iteration: 100% 437/439 [26:57<00:07,  3.68s/it]\u001b[A\n",
            "Iteration: 100% 438/439 [27:00<00:03,  3.68s/it]\u001b[A\n",
            "Epoch: 100% 1/1 [27:03<00:00, 1623.45s/it]\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   guid: dev-0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   tokens: CR ##IC ##KE ##T - L ##EI ##CE ##ST ##ER ##S ##H ##IR ##E T ##A ##KE O ##VE ##R AT TO ##P A ##FT ##ER IN ##NI ##NG ##S VI ##CT ##OR ##Y .\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_ids: 101 15531 9741 22441 1942 118 149 27514 10954 9272 9637 1708 3048 18172 2036 157 1592 22441 152 17145 2069 13020 16972 2101 138 26321 9637 15969 27451 11780 1708 7118 16647 9565 3663 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   guid: dev-1\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   tokens: L ##ON ##D ##ON 1996 - 08 - 30\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_ids: 101 149 11414 2137 11414 1820 118 4775 118 1476 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   guid: dev-2\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   tokens: West Indian all - round ##er Phil Simmons took four for 38 on Friday as Leicestershire beat Somerset by an innings and 39 runs in two days to take over at the head of the county championship .\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_ids: 101 1537 1890 1155 118 1668 1200 5676 14068 1261 1300 1111 3383 1113 5286 1112 21854 3222 8860 1118 1126 6687 1105 3614 2326 1107 1160 1552 1106 1321 1166 1120 1103 1246 1104 1103 2514 2899 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   guid: dev-3\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   tokens: Their stay on top , though , may be short - lived as title rivals Essex , Derbyshire and Surrey all closed in on victory while Kent made up for lost time in their rain - affected match against Nottinghamshire .\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_ids: 101 2397 2215 1113 1499 117 1463 117 1336 1129 1603 118 2077 1112 1641 9521 8493 117 15964 1105 9757 1155 1804 1107 1113 2681 1229 5327 1189 1146 1111 1575 1159 1107 1147 4458 118 4634 1801 1222 21942 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   *** Example ***\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   guid: dev-4\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   tokens: After bowling Somerset out for 83 on the opening morning at Grace Road , Leicestershire extended their first innings by 94 runs before being bowled out for 29 ##6 with England disc ##ard Andy C ##ad ##dick taking three for 83 .\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_ids: 101 1258 11518 8860 1149 1111 6032 1113 1103 2280 2106 1120 4378 1914 117 21854 2925 1147 1148 6687 1118 5706 2326 1196 1217 21663 1149 1111 1853 1545 1114 1652 6187 2881 4827 140 3556 25699 1781 1210 1111 6032 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/01/2021 10:08:04 - INFO - __main__ -   ***** Running evaluation *****\n",
            "06/01/2021 10:08:04 - INFO - __main__ -     Num examples = 3250\n",
            "06/01/2021 10:08:04 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 407/407 [01:09<00:00,  5.88it/s]\n",
            "06/01/2021 10:09:14 - INFO - __main__ -   \n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        PER     0.9558    0.9750    0.9653      1842\n",
            "        LOC     0.9562    0.9510    0.9536      1837\n",
            "        ORG     0.8889    0.9128    0.9007      1341\n",
            "       MISC     0.8468    0.8753    0.8608       922\n",
            "\n",
            "avg / total     0.9239    0.9381    0.9309      5942\n",
            "\n",
            "06/01/2021 10:09:14 - INFO - __main__ -   ***** Eval results *****\n",
            "06/01/2021 10:09:14 - INFO - __main__ -   \n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        PER     0.9558    0.9750    0.9653      1842\n",
            "        LOC     0.9562    0.9510    0.9536      1837\n",
            "        ORG     0.8889    0.9128    0.9007      1341\n",
            "       MISC     0.8468    0.8753    0.8608       922\n",
            "\n",
            "avg / total     0.9239    0.9381    0.9309      5942\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQI0PpxMoSLm"
      },
      "source": [
        "### **Prediction:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpM2Nr8-ZfEP"
      },
      "source": [
        "'pwd' command used to check the path of the directory. As we have all the required files and folders inside 'BERT-NER' folder, we are verfying it by this command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGjEwpZRBRV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d1aeeaf-bbf5-44e2-e6bc-d77de5f040e9"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/BERT-NER'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZS05_lvaQwt"
      },
      "source": [
        "**Overwrite 'bert.py' files:**\n",
        "> In 'bert.py' we have made changes for better representation and display of '**entity detected**' and their '**entity types**' for the given sentence to test or inference.\n",
        ">Overwrite the 'bert.py' by using below command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4qc2xmMA_z8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a711ea7c-9539-446b-eee1-63611468c32a"
      },
      "source": [
        "%%writefile bert.py\n",
        "\"\"\"BERT NER Inference.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from nltk import word_tokenize\n",
        "from pytorch_transformers import (BertConfig, BertForTokenClassification,\n",
        "                                  BertTokenizer)\n",
        "\n",
        "\n",
        "class BertNer(BertForTokenClassification):\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, valid_ids=None):\n",
        "        sequence_output = self.bert(input_ids, token_type_ids, attention_mask, head_mask=None)[0]\n",
        "        batch_size,max_len,feat_dim = sequence_output.shape\n",
        "        valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32,device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        for i in range(batch_size):\n",
        "            jj = -1\n",
        "            for j in range(max_len):\n",
        "                    if valid_ids[i][j].item() == 1:\n",
        "                        jj += 1\n",
        "                        valid_output[i][jj] = sequence_output[i][j]\n",
        "        sequence_output = self.dropout(valid_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "        return logits\n",
        "\n",
        "class Ner:\n",
        "\n",
        "    def __init__(self,model_dir: str):\n",
        "        self.model , self.tokenizer, self.model_config = self.load_model(model_dir)\n",
        "        self.label_map = self.model_config[\"label_map\"]\n",
        "        self.max_seq_length = self.model_config[\"max_seq_length\"]\n",
        "        self.label_map = {int(k):v for k,v in self.label_map.items()}\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "    def load_model(self, model_dir: str, model_config: str = \"model_config.json\"):\n",
        "        model_config = os.path.join(model_dir,model_config)\n",
        "        model_config = json.load(open(model_config))\n",
        "        model = BertNer.from_pretrained(model_dir)\n",
        "        tokenizer = BertTokenizer.from_pretrained(model_dir, do_lower_case=model_config[\"do_lower\"])\n",
        "        return model, tokenizer, model_config\n",
        "\n",
        "    def tokenize(self, text: str):\n",
        "        \"\"\" tokenize input\"\"\"\n",
        "        words = word_tokenize(text)\n",
        "        tokens = []\n",
        "        valid_positions = []\n",
        "        for i,word in enumerate(words):\n",
        "            token = self.tokenizer.tokenize(word)\n",
        "            tokens.extend(token)\n",
        "            for i in range(len(token)):\n",
        "                if i == 0:\n",
        "                    valid_positions.append(1)\n",
        "                else:\n",
        "                    valid_positions.append(0)\n",
        "        return tokens, valid_positions\n",
        "\n",
        "    def preprocess(self, text: str):\n",
        "        \"\"\" preprocess \"\"\"\n",
        "        tokens, valid_positions = self.tokenize(text)\n",
        "        ## insert \"[CLS]\"\n",
        "        tokens.insert(0,\"[CLS]\")\n",
        "        valid_positions.insert(0,1)\n",
        "        ## insert \"[SEP]\"\n",
        "        tokens.append(\"[SEP]\")\n",
        "        valid_positions.append(1)\n",
        "        segment_ids = []\n",
        "        for i in range(len(tokens)):\n",
        "            segment_ids.append(0)\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_mask = [1] * len(input_ids)\n",
        "        while len(input_ids) < self.max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "            segment_ids.append(0)\n",
        "            valid_positions.append(0)\n",
        "        return input_ids,input_mask,segment_ids,valid_positions\n",
        "\n",
        "    def predict(self, text: str):\n",
        "        input_ids,input_mask,segment_ids,valid_ids = self.preprocess(text)\n",
        "        input_ids = torch.tensor([input_ids],dtype=torch.long,device=self.device)\n",
        "        input_mask = torch.tensor([input_mask],dtype=torch.long,device=self.device)\n",
        "        segment_ids = torch.tensor([segment_ids],dtype=torch.long,device=self.device)\n",
        "        valid_ids = torch.tensor([valid_ids],dtype=torch.long,device=self.device)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(input_ids, segment_ids, input_mask,valid_ids)\n",
        "        logits = F.softmax(logits,dim=2)\n",
        "        logits_label = torch.argmax(logits,dim=2)\n",
        "        logits_label = logits_label.detach().cpu().numpy().tolist()[0]\n",
        "\n",
        "        logits_confidence = [values[label].item() for values,label in zip(logits[0],logits_label)]\n",
        "\n",
        "        logits = []\n",
        "        pos = 0\n",
        "        for index,mask in enumerate(valid_ids[0]):\n",
        "            if index == 0:\n",
        "                continue\n",
        "            if mask == 1:\n",
        "                logits.append((logits_label[index-pos],logits_confidence[index-pos]))\n",
        "            else:\n",
        "                pos += 1\n",
        "        logits.pop()\n",
        "\n",
        "        labels = [(self.label_map[label],confidence) for label,confidence in logits]\n",
        "        words = word_tokenize(text)\n",
        "        assert len(labels) == len(words)\n",
        "\n",
        "        Person = []\n",
        "        Location = []\n",
        "        Organization = []\n",
        "        Miscelleneous = []\n",
        "\n",
        "        for word, (label, confidence) in zip(words, labels):\n",
        "            if label==\"B-PER\" or label==\"I-PER\":\n",
        "                Person.append(word)\n",
        "            elif label==\"B-LOC\" or label==\"I-LOC\":\n",
        "                Location.append(word)\n",
        "            elif label==\"B-ORG\" or label==\"I-ORG\":\n",
        "                Organization.append(word)\n",
        "            elif label==\"B-MISC\" or label==\"I-MISC\":\n",
        "                Miscelleneous.append(word)\n",
        "            else:\n",
        "                output = None\n",
        "\n",
        "        output = []\n",
        "        for word, (label, confidence) in zip(words, labels):      \n",
        "            if label == \"B-PER\":\n",
        "                output.append(' '.join(Person) + \": Person\")\n",
        "            if label==\"B-LOC\":\n",
        "                output.append(' '.join(Location) + \": Location\")\n",
        "            if label==\"B-MISC\":\n",
        "                output.append(' '.join(Miscelleneous) + \": Miscelleneous Entity\")\n",
        "            if label==\"B-ORG\":\n",
        "                output.append(' '.join(Organization) + \": Organization\")\n",
        "                \n",
        "        return output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting bert.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qrjg_s-c99d"
      },
      "source": [
        "Run below command for import and download 'nltk' library as it is important for predictions of entities of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJpTRPE2rOQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa728bd-bb84-4c26-a7c7-19afd40a9671"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehDh-U_fdkQW"
      },
      "source": [
        "Run the below cell for final output: \n",
        "\n",
        ">In the below cell first line we call the '**Ner**' class from the 'bert.py' file. '**Ner**' class intialize our fine-tuned model.\n",
        "\n",
        ">Store the model in any variable. In below cell we store our fine-tuned model into 'model' variable.\n",
        "\n",
        "> Pass any text as a string for entity detection. We pass \"Bob Ross lived in Florida.\" in 'text' variable for below cell.\n",
        "\n",
        "> Use '**predict**' function of class '**Ner**' for detecting entities for the 'text' and stored it into 'output'. In 'output' variable we have a detected entities of list.\n",
        "\n",
        "> Run 'for loop' for list formed 'output'. Print the 'prediction' of 'for loop'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRseIPZ1rcEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3471df78-df78-4aa1-927c-a7d3ae7725ca"
      },
      "source": [
        "from bert import Ner\n",
        "model = Ner(\"out_ner/\")\n",
        "\n",
        "text= \"The U.S. President Donald Trump came to visit Ahmedabad first time at Motera Stadium with our Prime Minister Narendra Modi in February 2020.\"\n",
        "print(\"Text to predict Entity:\", text)\n",
        "\n",
        "output = model.predict(text)\n",
        "for prediction in output:\n",
        "    print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to predict Entity: The U.S. President Donald Trump came to visit Ahmedabad first time at Motera Stadium with our Prime Minister Narendra Modi in February 2020.\n",
            "U.S. Ahmedabad Motera Stadium: Location\n",
            "Donald Trump Narendra Modi: Person\n",
            "U.S. Ahmedabad Motera Stadium: Location\n",
            "U.S. Ahmedabad Motera Stadium: Location\n",
            "Donald Trump Narendra Modi: Person\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}