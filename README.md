# END-NLP-Projects
This repo contains all my nlp work and learning. Made public so that others can learn and get benefits.The repo will contain all my project related to NLP learning and vision model deployment using mediapipe.

![image](https://media.giphy.com/media/YknAouVrcbkiDvWUOR/giphy.gif)

![image](https://media.giphy.com/media/26xBtSyoi5hUUkCEo/giphy.gif)

![image](https://media.giphy.com/media/3o6Ztg5jGKDQSjaZ1K/giphy.gif)

## Curated resource in NLP
This section will contain my curated resources which helped me during NLP learning
For NLP, [@quantum_stat](https://twitter.com/Quantum_Stat),[amitness](https://twitter.com/amitness) ,[Stanford NLP Group](https://twitter.com/stanfordnlp) and [@nlpguy_'s](https://twitter.com/nlpguy_) curation of resources and experience is super-helpful.

- Data: http://datasets.quantumstat.com
- Model selection: http://models.pratik.ai
- Models: http://models.quantumstat.com
- Notebook: http://notebooks.quantumstat.com
- Deployment: http://deployment.pratik.ai
- [CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/)
- [Natural Language Processing with Python](http://www.nltk.org/book/)
- [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)
- [A Visual Survey of Data Augmentation in NLP](https://amitness.com/2020/05/data-augmentation-for-nlp/)
- [NLP Augmentation Package](https://github.com/makcedward/nlpaug)
- [Allen NLP](https://allennlp.org/)
- [Simple Transformers](https://simpletransformers.ai/)
- [Automatically Generate True or False questions from any content with OpenAI GPT2, Sentence BERT and Berkley Constituency parse](https://medium.com/swlh/practical-ai-automatically-generate-true-or-false-questions-from-any-content-with-openai-gpt2-9081ffe4d4c9)
- [Generative Model Chatbots](https://medium.com/botsupply/generative-model-chatbots-e422ab08461e)
- [Deep Learning for Chatbots, Part 1 – Introduction](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/?subscribe=success#blog_subscription-2)
- [Natural Language Understanding for Chatbots](https://medium.com/neuralspace/natural-language-understanding-for-chatbots-2eb7a81b9390)
- [Indic Transformers: An Analysis of Transformer Language Models for Indian Languages](https://medium.com/neuralspace/indic-transformers-an-analysis-of-transformer-language-models-for-indian-languages-c6b4db0643b)
- [How Does Attention Work in Encoder-Decoder Recurrent Neural Networks](https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/)

### Convolution for Text
- [Convolutional Sequence to Sequence Learning](https://charon.me/posts/pytorch/pytorch_seq2seq_5/)
- [Sequence models & Attention mechanism](https://charon.me/posts/dl/dl15/)


### BERT
- [BERT (Word Embeddings)](https://charon.me/posts/nlp/bert/)

### GPT2
- [How GPT 2 works](https://charon.me/posts/model/gpt-2/)

### Convolution for NLP
- [Translation Pytorch Tutorial NLP Part: Use TorchText for Text Classification](https://www.programmersought.com/article/93015028948/)
- [CNNs for Text Classification](https://cezannec.github.io/CNN_Text_Classification/)
- [Extracting Keyphrases from Text: RAKE and Gensim in Python](https://medium.com/@nikitasaxena0209)
- [PyTorch: Scene Text Detection and Recognition by CRAFT and a Four-Stage Network](https://towardsdatascience.com/pytorch-scene-text-detection-and-recognition-by-craft-and-a-four-stage-network-ec814d39db05)
- [CNN Text Classification](https://github.com/amitkml/CNN_Text_Classification)

### Attention? Attention is what you need!
- [Attention why?](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)
- [Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 8 – Translation, Seq2Seq, Attention](https://www.youtube.com/watch?v=XXtpJxZBa2c)
- [Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 14 – Transformers and Self-Attention](https://www.youtube.com/watch?v=5vcj8kSwBCY)
- [TRANSFORMERS FROM SCRATCH](http://peterbloem.nl/blog/transformers)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
 
## Curated repo for NLP
- https://github.com/bentrevett/pytorch-seq2seq
- [SNU 4th Industrial Revolution Academy: Artificial Intelligence Agent](http://ling.snu.ac.kr/class/AI_Agent/)
- [Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 11 – Convolutional Networks for NLP](https://www.youtube.com/watch?v=EAJoRA0KX7I)
- [Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 8 – Translation, Seq2Seq, Attention](https://www.youtube.com/watch?v=XXtpJxZBa2c)

## Details on Medipipe

I am going to follow [End To End Project Example In Mediapipe](https://medium.com/@mahakal001/end-to-end-project-example-in-mediapipe-b74a4a8ebb61) and github issue [How to put my own Trained model in mediapipe?](https://github.com/google/mediapipe/issues/507)for adding my model into mediapipe.

More details on mediapipe can be found from [Background Features in Google Meet, Powered by Web ML](https://www.googblogs.com/tag/machine-perception/)
