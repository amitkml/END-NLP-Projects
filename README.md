# END-NLP-Projects
This repo contains all my nlp work and learning. Made public so that others can learn and get benefits.The repo will contain all my project related to NLP learning and vision model deployment using mediapipe.

![image](https://media.giphy.com/media/YknAouVrcbkiDvWUOR/giphy.gif)

![image](https://media.giphy.com/media/26xBtSyoi5hUUkCEo/giphy.gif)

![image](https://media.giphy.com/media/3o6Ztg5jGKDQSjaZ1K/giphy.gif)

## Curated resource in NLP
This section will contain my curated resources which helped me during NLP learning
For NLP, [@quantum_stat](https://twitter.com/Quantum_Stat),[amitness](https://twitter.com/amitness) and [@nlpguy_'s](https://twitter.com/nlpguy_) curation of resources and experience is super-helpful.

- Data: http://datasets.quantumstat.com
- Model selection: http://models.pratik.ai
- Models: http://models.quantumstat.com
- Notebook: http://notebooks.quantumstat.com
- Deployment: http://deployment.pratik.ai
- [A Visual Survey of Data Augmentation in NLP](https://amitness.com/2020/05/data-augmentation-for-nlp/)
- [NLP Augmentation Package](https://github.com/makcedward/nlpaug)
- [Allen NLP](https://allennlp.org/)
- [Simple Transformers](https://simpletransformers.ai/)
- [Automatically Generate True or False questions from any content with OpenAI GPT2, Sentence BERT and Berkley Constituency parse](https://medium.com/swlh/practical-ai-automatically-generate-true-or-false-questions-from-any-content-with-openai-gpt2-9081ffe4d4c9)
- [Generative Model Chatbots](https://medium.com/botsupply/generative-model-chatbots-e422ab08461e)
- [Deep Learning for Chatbots, Part 1 â€“ Introduction](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/?subscribe=success#blog_subscription-2)
- [Natural Language Understanding for Chatbots](https://medium.com/neuralspace/natural-language-understanding-for-chatbots-2eb7a81b9390)
- [Indic Transformers: An Analysis of Transformer Language Models for Indian Languages](https://medium.com/neuralspace/indic-transformers-an-analysis-of-transformer-language-models-for-indian-languages-c6b4db0643b)
- [How Does Attention Work in Encoder-Decoder Recurrent Neural Networks](https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/)


## Details on Medipipe

I am going to follow [End To End Project Example In Mediapipe](https://medium.com/@mahakal001/end-to-end-project-example-in-mediapipe-b74a4a8ebb61) and github issue [How to put my own Trained model in mediapipe?](https://github.com/google/mediapipe/issues/507)for adding my model into mediapipe.

More details on mediapipe can be found from [Background Features in Google Meet, Powered by Web ML](https://www.googblogs.com/tag/machine-perception/)
