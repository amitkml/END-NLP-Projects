{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment Analysis using Naive Bayes.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrrP2fw91eCe/rYwptPE8i"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I4tgyjYGU5mh"},"source":["# Sentiment Analysis using Naive Bayes\n","\n","In this assignment, we will attempt to label tweets with sentiments (positive, neutral and negative) using Naive Bayes classifier. Naive Bayes is a very basic approach to this problem, but gives surprisingly good accuracy sometimes.\n","\n","**Fill in the Blanks**"]},{"cell_type":"markdown","metadata":{"id":"Af8UfnQOVXGZ"},"source":["## Importing required libraries"]},{"cell_type":"code","metadata":{"id":"91xo5PKAUoux"},"source":["import pandas as pd\n","import re\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uEeXoKyvVqdQ"},"source":["## Reading dataset"]},{"cell_type":"code","metadata":{"id":"menn3WewVpe9"},"source":["data=pd.read_csv('tweets.csv')\n","data.drop(data.columns[0],axis=1,inplace=True)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1bUNORaDVwrN"},"source":["## Text processing for the tweets"]},{"cell_type":"code","metadata":{"id":"gCtQLFwcHauQ"},"source":["import nltk \n","nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbVn9swJVuLA"},"source":["from nltk.tokenize import word_tokenize\n","from string import punctuation \n","from nltk.corpus import stopwords \n","\n","stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])\n","    \n","def processTweet(tweet):\n","    # tweet is the text we will pass for preprocessing \n","    # convert passed tweet to lower case \n","    --Fill--\n","    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n","    tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n","    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n","    \n","    # use work_tokenize imported above to tokenize the tweet\n","    --Fill--\n","    return [word for word in tweet if word not in stopwords]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6gk8veQrWK7J"},"source":["## Process all tweets"]},{"cell_type":"code","metadata":{"id":"44jBcZrTV1QQ"},"source":["processed=[]\n","\n","for tweet in data['tweets']:\n","    \n","    # process all tweets using processTweet function above - store in variable 'cleaned' \n","    cleaned=processTweet(tweet)\n","    processed.append(' '.join(cleaned))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQ_2PZV-WO_E"},"source":["data['processed'] = processed"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JabmRdNiWUhc"},"source":["## Create pipeline and define parameters for GridSearch"]},{"cell_type":"code","metadata":{"id":"azZvCgLsWVaZ"},"source":["text_clf = Pipeline([('vect', CountVectorizer()),\n","                     ('tfidf', TfidfTransformer()),\n","                     ('clf', MultinomialNB())])\n","\n","tuned_parameters = {\n","    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n","    'tfidf__use_idf': (True, False),\n","    'tfidf__norm': ('l1', 'l2'),\n","    'clf__alpha': [1, 1e-1, 1e-2]\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-0xeqceWWbz_"},"source":["## Split data into test and train"]},{"cell_type":"code","metadata":{"id":"uznVuAUUWbPM"},"source":["# split data into train and test with split as 0.2 \n","X = data.processed\n","y = data.labels\n","\n","--Fill--"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y1ZgcaM8WfRB"},"source":["## Perform classification (using GridSearch)"]},{"cell_type":"code","metadata":{"id":"AUwwb2IWWhmH"},"source":["# perform GridSearch CV with 10 fold CV using pipeline and tuned_paramters defined above \n","clf = --Fill--\n","clf.fit(x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CE_mfhiUWyc8"},"source":["## Classification report "]},{"cell_type":"code","metadata":{"id":"rqvkzGFRWzIb"},"source":["# print classification report after predicting on test set with best model obtained in GridSearch\n","--Fill--"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"shTpptLeW1SF"},"source":["## Important:"]},{"cell_type":"code","metadata":{"id":"OdWycpFYW3iD"},"source":["counts = data.labels.value_counts()\n","print(counts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6l3PcKXfW9LE"},"source":["We can see above that the class distribution is highly imbalanced, this would not lead to good sampling of the data for the classifier. For your learning, try using [SMOTE](https://imbalanced-learn.readthedocs.io/en/stable/api.html) to oversample the minority classes and then evaluate the performance with Naive Bayes and compare."]}]}